{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyDrive\n",
    "!pip install keras --upgrade\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authorise google SDK to use drive\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the shareable link on google, get the id and paste like this\n",
    "\n",
    "# get annotations file\n",
    "download = drive.CreateFile({'id':'1XHHRjyRyq1wNnmaP6ZRn7c12qID9J-M9'})\n",
    "download.GetContentFile('Annotations.zip')\n",
    "\n",
    "# get signals file\n",
    "download = drive.CreateFile({'id':'17JL1xg5wNnl8ck8VqYsvpABxdAIrdlBi'})\n",
    "download.GetContentFile('Signals.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the zipfiles\n",
    "\n",
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile('Annotations.zip', 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "zip_ref = zipfile.ZipFile('Signals.zip', 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' IMPORT AUDIO SIGNALS '''\n",
    "\n",
    "# Write signal data to variables\n",
    "from scipy.io import wavfile\n",
    "import wave\n",
    "import numpy as np\n",
    "samprate = 44100\n",
    "\n",
    "def get_wav(file_name, nsamples):\n",
    "    wav = wavfile.read(file_name)[1]\n",
    "    signal = wav[0:nsamples]\n",
    "    return signal\n",
    "\n",
    "filepath = \"/users/garethjones/Documents/Data Science/Feebris/Data/Clean Stethoscope/\"\n",
    "\n",
    "# work out length of each sample in frames\n",
    "sampleframes = []\n",
    "for i in range(1,11):\n",
    "    sample = wave.open(filepath+\"Signals/Signal {}.wav\".format(i),'r')\n",
    "    nframes = sample.getnframes()\n",
    "    sampleframes.append(nframes)\n",
    "    \n",
    "# import signals and store\n",
    "signals = [get_wav(filepath+\"Signals/Signal {}.wav\".format(i+1),sampleframes[i]*2) for i in range(10)]\n",
    "    \n",
    "# create list of second intervals for each sample\n",
    "samplesecs = [np.arange(1,len(signals[i])+1) / samprate for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' IMPORT ANNOTATION AUDIO SIGNALS '''\n",
    "\n",
    "# work out length of each sample in frames\n",
    "annotationframes = []\n",
    "for i in range(1,11):\n",
    "    sample = wave.open(filepath+\"Annotations/Annotation {}.wav\".format(i),'r')\n",
    "    nframes = sample.getnframes()\n",
    "    annotationframes.append(nframes)\n",
    "    \n",
    "# import signals and store\n",
    "annotations = [get_wav(filepath+\"Annotations/Annotation {}.wav\".format(i+1),annotationframes[i]*2) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NORMALIZE SIGNALS TO 1 '''\n",
    "\n",
    "# Normalize signals\n",
    "for i in range(len(signals)):\n",
    "    signals[i] = signals[i] / (2.**15)\n",
    "\n",
    "for i in range(len(annotations)):\n",
    "    annotations[i] = annotations[i] / (2.**15)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CUT OUT SIGNALS WHERE ANNOTATIONS ARE NOT CLEAR '''\n",
    "\n",
    "# set all signals to be the length of annotations\n",
    "for i in range(len(signals)):\n",
    "    signals[i] = signals[i][0:len(annotations[i])]\n",
    "\n",
    "# pre-process signals 1,2,7 specifically due to poor click annotations\n",
    "signals[0] = signals[0][0:2700000]\n",
    "annotations[0] = annotations[0][0:2700000]\n",
    "\n",
    "signals[1] = signals[1][0:2650000]\n",
    "annotations[1] = annotations[1][0:2650000]\n",
    "\n",
    "signals[6] = signals[6][0:2800000]\n",
    "annotations[6] = annotations[6][0:2800000]\n",
    "\n",
    "# test to ensure lengths are the same\n",
    "for i in range(len(signals)):\n",
    "    assert len(signals[i]) == len(annotations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CUT SIGNALS TO SHORTEST LENGTH (FOR EQUAL SIZED SPECTOGRAMS) '''\n",
    "\n",
    "# to ensure spectograms work well, I need to cut the data at 2,650,000, the shortest sample length, so everything is same length\n",
    "# get all signal lengths\n",
    "signallen = [len(signals[i]) for i in range(len(signals))] \n",
    "\n",
    "for i in range(len(signals)):\n",
    "    signals[i] = signals[i][0:min(signallen)]\n",
    "\n",
    "for i in range(len(signals)):\n",
    "    annotations[i] = annotations[i][0:min(signallen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' VISUALISE '''\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "fig,ax = plt.subplots(1,1,figsize=(20,8))\n",
    "ax.plot(annotations[6])\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(125000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' IMPORTS & GLOBALS '''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from librosa.display import specshow\n",
    "from librosa.feature import melspectrogram\n",
    "import pylab\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "samprate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MAKE SIGNALS MONO AUDIO '''\n",
    "\n",
    "# select only one channel of stereo signal, and transpose ready for melspectogram\n",
    "signals_mono = [signals[i].T[0] for i in range(len(signals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GENERATE MEL SPECTOGRAMS FOR SIGNALS '''\n",
    "\n",
    "hop_length = 2550  # number of frames to jump when computing fft\n",
    "fmin = 125  # bottom frequency to look at\n",
    "fmax = 500  # top frequency to look at\n",
    "n_mels = 45  # number of audio frequency bins\n",
    "n_fft = [8000, 11025, 14000]  # width of the fft windows\n",
    "\n",
    "\n",
    "# list of 10 mels, with depth 3\n",
    "mel_db_list = []\n",
    "\n",
    "for i in range(len(signals_mono)):\n",
    "    \n",
    "    mel = [melspectrogram(\n",
    "            signals_mono[i],\n",
    "            sr = samprate,\n",
    "            hop_length = 2550,\n",
    "            n_fft = j,\n",
    "            n_mels = 45,\n",
    "            fmin = 125,\n",
    "            fmax = 500) for j in n_fft]\n",
    "    \n",
    "    mel_db = [librosa.power_to_db(mel[k],ref=np.max) for k in range(len(mel))]\n",
    "    \n",
    "    mel_db = np.stack(mel_db,axis=-1)\n",
    "    \n",
    "    mel_db_list.append(mel_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Annotation Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' GLOBAL VARIABLES & REFERENCE '''\n",
    "\n",
    "# known clicks per sample\n",
    "originalclickspersignal = {\n",
    "        'Annotation 1' : 24, 'Annotation 2' : 20, 'Annotation 3' : 24, 'Annotation 4' : 34, 'Annotation 5' : 30,\n",
    "        'Annotation 6' : 31, 'Annotation 7' : 32, 'Annotation 8' : 36, 'Annotation 9' : 33, 'Annotation 10' : 29\n",
    "        }\n",
    "\n",
    "# these are number of clicks per sample after chopping data\n",
    "newclickspersignal = {\n",
    "        'Annotation 1' : 22, 'Annotation 2' : 19, 'Annotation 3' : 22, 'Annotation 4' : 33, 'Annotation 5' : 28,\n",
    "        'Annotation 6' : 30, 'Annotation 7' : 31, 'Annotation 8' : 29, 'Annotation 9' : 29, 'Annotation 10' : 26\n",
    "        }\n",
    "\n",
    "# eye-balled thresholds for each signal\n",
    "thresholds = {\n",
    "        'Annotation 1' : 0.1, 'Annotation 2' : 0.1, 'Annotation 3' : 0.07, 'Annotation 4' : 0.1, 'Annotation 5' : 0.03,\n",
    "        'Annotation 6' : 0.1, 'Annotation 7' : 0.095, 'Annotation 8' : 0.1, 'Annotation 9' : 0.05, 'Annotation 10' : 0.1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' MAKE ANNOTATION SIGNALS MONO '''\n",
    "\n",
    "# make annotations one channel, transposed, absolute\n",
    "annotations_mono = []\n",
    "for i in range(len(annotations)):\n",
    "    x = abs(annotations[i].T[0])\n",
    "    annotations_mono.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TURN SIGNALS INTO STEP FUNCTIONS '''\n",
    "\n",
    "# denote whenever amplitude is above threshold\n",
    "anno_gates = []\n",
    "for i in range(len(annotations_mono)):\n",
    "    gate_list = []\n",
    "    for j in range(len(annotations_mono[i])):\n",
    "        if annotations_mono[i][j] > thresholds['Annotation {}'.format(i+1)]: # this is amplitude threshold\n",
    "            x = 1\n",
    "        else:\n",
    "            x = 0\n",
    "        gate_list.append(x)\n",
    "    anno_gates.append(gate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SUPRESS NOISE IN STEP FUNCTION '''\n",
    "\n",
    "# ensure noise is removed so there's exact number of clicks\n",
    "fwd_frame_thresh = 15000\n",
    "size_anno_gates = []\n",
    "for i in range(len(anno_gates)):\n",
    "    for j in range(len(anno_gates[i])):\n",
    "        if anno_gates[i][j] == 1:\n",
    "            for k in range(1,fwd_frame_thresh): # this is the forward threshold for silencing frames\n",
    "                if j+k < len(anno_gates[i]):\n",
    "                    anno_gates[i][j+k] = 0\n",
    "                else:\n",
    "                    k = fwd_frame_thresh - j\n",
    "                    anno_gates[i][j+k] = 0       \n",
    "    size_anno_gates.append(sum(anno_gates[i]))\n",
    "\n",
    "print(np.r_[list(newclickspersignal.values())] - np.r_[size_anno_gates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' REDUCE ANNOTATIONS TO LENGTH OF MEL SPECTROGRAM '''\n",
    "\n",
    "# set the search window and hop size to same as the melspectrogram\n",
    "hop_size = 2550\n",
    "search_window = 11025\n",
    "\n",
    "# find index points to look at in annotation signal\n",
    "indices = list(np.arange(0,len(anno_gates[0]),2550))\n",
    "\n",
    "# now look across the annotation signal and max if there's a 1 in the window frame\n",
    "labels_list = []\n",
    "for i in range(len(anno_gates)):\n",
    "    labels = []\n",
    "    \n",
    "    for j in indices:    \n",
    "        if ((j - search_window/2) > 0) & ((j + search_window/2) < len(anno_gates[i])):\n",
    "            label_window = anno_gates[i][int(j-search_window/2):int(j+search_window/2)]\n",
    "            max_label = max(label_window)\n",
    "            labels.append(max_label)\n",
    "        \n",
    "        elif (j - search_window/2) < 0:\n",
    "            label_window = anno_gates[i][0:int(j+search_window/2)]\n",
    "            max_label = max(label_window)\n",
    "            labels.append(max_label)\n",
    "        \n",
    "        elif (j + search_window/2) > len(anno_gates[i]):\n",
    "            label_window = anno_gates[i][int(j-search_window/2):len(anno_gates[i])]\n",
    "            max_label = max(label_window)\n",
    "            labels.append(max_label)\n",
    "    \n",
    "    labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' VISUALISE '''\n",
    "fig,axs = plt.subplots(2,1,figsize=(12,8))\n",
    "axs[0].plot(labels_list[2])\n",
    "axs[0].set_title('New Labels (1040 Frames)')\n",
    "axs[1].plot(anno_gates[2])\n",
    "axs[1].set_title('Original Annotation Signal')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and Prep Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' NEED SOMEONE TO CHECK THIS CODE FOR ME '''\n",
    "\n",
    "''' CHOP SPECTOGRAMS AND NORMALIZE '''\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "window_len = 15\n",
    "\n",
    "mel_slices_normed_list = []\n",
    "for i in range(len(mel_db_list)):\n",
    "    \n",
    "    for j in range(mel_db.shape[1]-15):\n",
    "        slices = mel_db_list[i][:,j:j+15,:]\n",
    "        # normalize to zero mean and unit variance along rows of each spectogram within each slice\n",
    "        # consider looking at this along columns as well, may improve training?\n",
    "        slices_normed = [scale(slices[:,:,k],axis=1) for k in range(3)]\n",
    "        # stacks elements of list back into a single numpy array\n",
    "        slices_normed = np.stack(slices_normed,axis=-1)\n",
    "        # puts theses single arrays into a list, length of one signal\n",
    "        mel_slices_normed_list.append(slices_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CREATE NEW LABELS FOR EACH FRAME '''\n",
    "\n",
    "# looks for the labels at the middle value of each mel spectrogram slice of window size 15\n",
    "labels_list_shrunk = []\n",
    "for i in range(len(labels_list)):\n",
    "\n",
    "    for j in range(int(window_len/2),mel_db.shape[1]-int(window_len/2)-1):\n",
    "        \n",
    "        if labels_list[i][j] == 1:\n",
    "            x = 1\n",
    "        else:\n",
    "            x = 0\n",
    "        \n",
    "        labels_list_shrunk.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' COMPARE OLD AND NEW LABELS '''\n",
    "\n",
    "labels_sums = [sum(labels_list[i]) for i in range(len(labels_list))]\n",
    "labels_shrunk_sums = [sum(labels_list_shrunk[i*1025:(i+1)*1025]) for i in range(len(labels_list))]\n",
    "print('Original positive labels = ' + str(labels_sums))\n",
    "print('New shrunk positive labels = ' + str(labels_shrunk_sums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CHOOSE RANDOM SLICES AND LABELS FOR MODELLING '''\n",
    "# split data into training 70%, validation 20%, test 10%\n",
    "\n",
    "indices = np.arange(0,len(mel_slices_normed_list))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "indices_train = indices[0:int(0.7*len(mel_slices_normed_list))]\n",
    "indices_val = indices[int(0.7*len(mel_slices_normed_list)):int(0.9*len(mel_slices_normed_list))]\n",
    "indices_test = indices[int(0.9*len(mel_slices_normed_list)):len(mel_slices_normed_list)]\n",
    "\n",
    "assert len(indices_test)+len(indices_train)+len(indices_val) == len(mel_slices_normed_list)\n",
    "\n",
    "\n",
    "mel_slices_train = np.array([mel_slices_normed_list[i] for i in indices_train])\n",
    "labels_train = np.array([labels_list_shrunk[i] for i in indices_train])\n",
    "\n",
    "mel_slices_val = np.array([mel_slices_normed_list[i] for i in indices_val])\n",
    "labels_val = np.array([labels_list_shrunk[i] for i in indices_val])\n",
    "\n",
    "mel_slices_test = np.array([mel_slices_normed_list[i] for i in indices_test])\n",
    "labels_test = np.array([labels_list_shrunk[i] for i in indices_test])\n",
    "\n",
    "assert len(mel_slices_train) == len(labels_train)\n",
    "assert len(mel_slices_val) == len(labels_val)\n",
    "assert len(mel_slices_test) == len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build 2D Conv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DEFINE MODEL '''\n",
    "\n",
    "from keras import models,layers,optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,7),activation='relu',input_shape=(45,15,3)))\n",
    "model.add(layers.MaxPooling2D((3,1)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((3,1)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' COMPILE MODEL '''\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(lr=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TRAIN MODEL '''\n",
    "\n",
    "history = model.fit(\n",
    "        mel_slices_train,\n",
    "        labels_train,\n",
    "        batch_size=32,\n",
    "        epochs = 100,\n",
    "        validation_data = (mel_slices_val,labels_val),\n",
    "        verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
